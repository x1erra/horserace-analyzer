# Dockerfile for Live Horse Racing Crawler
# Runs continuous loop to crawl Equibase results hourly
# Designed for Raspberry Pi 5 (ARM64)

FROM python:3.11-slim

# Set working directory
WORKDIR /app

# Install system dependencies
# Install system dependencies including Chromium for Selenium and PowerShell (via tarball for ARM64)
RUN apt-get update && apt-get install -y \
  chromium \
  chromium-driver \
  chromium-common \
  libnss3 \
  libfontconfig1 \
  wget \
  ca-certificates \
  libicu-dev \
  && rm -rf /var/lib/apt/lists/* \
  && mkdir -p /opt/microsoft/powershell/7 \
  && wget -q https://github.com/PowerShell/PowerShell/releases/download/v7.4.1/powershell-7.4.1-linux-arm64.tar.gz \
  && tar -zxf powershell-7.4.1-linux-arm64.tar.gz -C /opt/microsoft/powershell/7 \
  && chmod +x /opt/microsoft/powershell/7/pwsh \
  && ln -s /opt/microsoft/powershell/7/pwsh /usr/bin/pwsh \
  && ln -s /opt/microsoft/powershell/7/pwsh /usr/bin/powershell \
  && rm powershell-7.4.1-linux-arm64.tar.gz

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy backend code
COPY backend/ backend/

# Create log directory
RUN mkdir -p /var/log && chmod 777 /var/log

# Environment variables (override these in Portainer/docker-compose)
ENV PYTHONUNBUFFERED=1
ENV SUPABASE_URL=""
ENV SUPABASE_SERVICE_KEY=""
# Set PYTHONPATH so python runs in the right context
ENV PYTHONPATH=/app/backend
# Set Log Directory to volume mount
ENV LOG_DIR=/var/log

# Healthcheck using the heartbeat file
HEALTHCHECK --interval=5m --timeout=10s --start-period=30s --retries=3 \
  CMD find /tmp/crawler_heartbeat -mmin -20 || exit 1

# Run crawler script
CMD ["python", "backend/live_crawl.py"]
